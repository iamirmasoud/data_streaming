{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcae0188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/12 12:52:44 WARN Utils: Your hostname, masoud-ubuntu resolves to a loopback address: 127.0.1.1; using 192.168.1.157 instead (on interface wlp2s0)\n",
      "23/09/12 12:52:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/12 12:52:54 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/12 12:53:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "\n",
    "conf = SparkConf().setMaster(\"local[2]\").setAppName(\"RDD Example\")\n",
    "sc = SparkContext(conf=conf)\n",
    "\n",
    "# different way of setting configurations\n",
    "# conf.setMaster('some url')\n",
    "# conf.set('spark.executor.memory', '2g')\n",
    "# conf.set('spark.executor.cores', '4')\n",
    "# conf.set('spark.cores.max', '40')\n",
    "# conf.set('spark.logConf', True)\n",
    "\n",
    "# sparkContext.parallelize materializes data into RDD\n",
    "# documentation: https://spark.apache.org/docs/2.1.1/programming-guide.html#parallelized-collections\n",
    "rdd = sc.parallelize(\n",
    "    [(\"Richard\", 22), (\"Alfred\", 23), (\"Loki\", 4), (\"Albert\", 12), (\"Alfred\", 9)]\n",
    ")\n",
    "\n",
    "rdd.collect()  # [('Richard', 22), ('Alfred', 23), ('Loki', 4), ('Albert', 12), ('Alfred', 9)]\n",
    "\n",
    "# create two different RDDs\n",
    "left = sc.parallelize([(\"Richard\", 1), (\"Alfred\", 4)])\n",
    "right = sc.parallelize([(\"Richard\", 2), (\"Alfred\", 5)])\n",
    "\n",
    "joined_rdd = left.join(right)\n",
    "collected = joined_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "653c3d1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Alfred', (4, 5)), ('Richard', (1, 2))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected  # [('Alfred', (4, 5)), ('Richard', (1, 2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0920346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Used in SparkSession Example\n",
    "# Notice weâ€™re using pyspark.sql library here\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"CSV file loader\").getOrCreate()\n",
    "\n",
    "# couple ways of setting configurations\n",
    "# spark.conf.set(\"spark.executor.memory\", '8g')\n",
    "# spark.conf.set('spark.executor.cores', '3')\n",
    "# spark.conf.set('spark.cores.max', '3')\n",
    "# spark.conf.set(\"spark.driver.memory\", '8g')\n",
    "\n",
    "file_path = \"data/AB_NYC_2019.csv\"\n",
    "# Always load csv files with header=True\n",
    "df = spark.read.csv(file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a685f17c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- host_id: string (nullable = true)\n",
      " |-- host_name: string (nullable = true)\n",
      " |-- neighbourhood_group: string (nullable = true)\n",
      " |-- neighbourhood: string (nullable = true)\n",
      " |-- latitude: string (nullable = true)\n",
      " |-- longitude: string (nullable = true)\n",
      " |-- room_type: string (nullable = true)\n",
      " |-- price: string (nullable = true)\n",
      " |-- minimum_nights: string (nullable = true)\n",
      " |-- number_of_reviews: string (nullable = true)\n",
      " |-- last_review: string (nullable = true)\n",
      " |-- reviews_per_month: string (nullable = true)\n",
      " |-- calculated_host_listings_count: string (nullable = true)\n",
      " |-- availability_365: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac9fa1e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 4:=============================>                             (1 + 1) / 2]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|neighbourhood|\n",
      "+-------------+\n",
      "|Corona       |\n",
      "|Richmondtown |\n",
      "|Prince's Bay |\n",
      "|Westerleigh  |\n",
      "|Mill Basin   |\n",
      "|40.76199     |\n",
      "|Civic Center |\n",
      "|40.83166     |\n",
      "|Douglaston   |\n",
      "|Mount Hope   |\n",
      "+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.select(\"neighbourhood\").distinct().show(10, False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
